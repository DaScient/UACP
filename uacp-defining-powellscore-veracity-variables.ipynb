{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dascient/uacp-defining-powellscore-veracity-variables?scriptVersionId=144252576\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# 2.0 UACP - Defining PowellScore & Veracity Variables\n## [1.0 UAP Analytic Centralization Program](https://www.kaggle.com/code/dascient/uacp-uap-analytic-centralization-program)\n<br>\n\n## [NLP - Sentiment Intensity Analyzer](https://github.com/cjhutto/vaderSentiment) Against Reporting Comments\n<br>\n\n### In collaboration with The Scientific Coalition for UAP Studies [(SCU)](ExploreSCU.org).\nHere we isolate only pertinent variables from the original dataset. We've also decided to leave open most of the code cells below; enabling transparency on foundation of all variables. ","metadata":{}},{"cell_type":"code","source":"%%time\n# for the sake of expeditious analysis\n!pip install xlrd\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom IPython.display import clear_output\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nfrom shapely.geometry import Point\nimport geopandas as gpd\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom geopandas import GeoDataFrame\nimport matplotlib.colors as colors\nimport seaborn as sns\nimport random as r\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        #print('Files loaded.')\n        \npd.set_option('display.max_colwidth', None)\n\n# loading first nuforc dataframe\nog_df1 = pd.read_csv('/kaggle/input/ufo-sightings/ufos.csv',header=0)\ndf = og_df1.dropna().copy()\nog_df2 = pd.read_csv('/kaggle/input/d/NUFORC/ufo-sightings/scrubbed.csv',header=0)\ndf2 = og_df2.dropna().copy()\n\n#############################################\n\nlex = pd.read_excel('/kaggle/input/scu-nlp-uap-lexicon/UFO lexicon rev2.xls',sheet_name='Sheet1',header=7)\nlex = lex.dropna(how='all').drop(columns='Unnamed: 0').copy()\n\n#############################################\n# sanitize\n# drop some columns, for now\ndf = df.drop(columns=['datetime','duration (hours/min)'])\n\n# date posted deemed to be easily conveible to timestamp values, so i'm gonna work with that for now.\ndf['date posted'] = df['date posted'].astype('datetime64[ns]')\n\n\n# length of comments\ndf['comment_length'] = [len(str(v[0:500])) for i,v in df.comments.items()]\n\n\n# convert seconds to minutes\ndf[\"duration (minutes)\"] = [int(v)/60 for i,v in df[\"duration (seconds)\"].items()]\n\n\n# creating Geo Point column for sopecial use below\ndf['Geo Point'] = df.apply(lambda x:'%s, %s' % (x['latitude'],x['longitude']),axis=1)\n\n\n# let's create subsets of our 80,000 here: \n# we can implement conditionals, remove/analyze outliers, \n# & will enable for back referencing when starting to run \n# robust AI-ML modeling that would otherwise take much longer to run.\n\n# let's create subsets from the main dataframe/reporting-data w/ respect to duration of observations\ndf_under100 = df[df[\"duration (minutes)\"]<100]\ndf_under60 = df[df[\"duration (minutes)\"]<60]\n\n# random binary column for future AI-ML modeling.\na=['balloon','spacejunk','sensor_malfunction','undentified','anomalous']     \ndf['verified'] = pd.Series(r.choices(a,k=len(df),weights=(50, 40, 30, 20, 10)),index=df.index)\n\n# shape-focused\ncircles = df[df['shape'] == 'circle']\nspheres = df[df['shape'] == 'sphere']\nlights = df[df['shape'] == 'light']\nteardrops = df[df['shape'] == 'teardrop']\n\n# year-month\ndf['year_month'] = df['date posted'].dt.to_period('M')\n\nclear_output()\n# show\nprint(\"\\nOriginal dataset.\")\nprint(f\"\\nReports: {len(df)} non-null dataframe.\")\nprint(\"\\nMatrix:\",df.shape[0],\"rows,\",df.shape[1],\"columns\")\ndf = df.sort_values('date posted',ascending=True).reset_index(drop=True)\ndf.tail(11).reset_index(drop=True).style.background_gradient(cmap ='seismic').set_properties(**{'font-size': '11px'}).set_properties(**{'text-align': 'left'})","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T00:55:14.061157Z","iopub.execute_input":"2023-09-26T00:55:14.061546Z","iopub.status.idle":"2023-09-26T00:55:30.684449Z","shell.execute_reply.started":"2023-09-26T00:55:14.061513Z","shell.execute_reply":"2023-09-26T00:55:30.683049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lexicon","metadata":{}},{"cell_type":"code","source":"#lex[lex['RATING']!=0]\n#lex[lex['Previous Rating']!=0]\n# non-zero rating words\nlex_nonzero = lex[lex['RATING']!=0]\n\n#lex[lex['Previous Rating']>=3]\n# rating words gerater than or equal to 3\n#lex_nonzero = lex[lex['RATING']>=3]\nlex_nonzero","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T01:51:26.878873Z","iopub.execute_input":"2023-09-26T01:51:26.879298Z","iopub.status.idle":"2023-09-26T01:51:26.898577Z","shell.execute_reply.started":"2023-09-26T01:51:26.879266Z","shell.execute_reply":"2023-09-26T01:51:26.897568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hash through each comment to find only those that include non-zero lexicon words. ","metadata":{}},{"cell_type":"code","source":"%%time\nimport time\nfrom nltk.tokenize import word_tokenize\n\ndf_sample = df.sample(1000)\n\n# hash through each comment to find only those that include non-zero lexicon words\nlexicon_favored = df_sample.copy()\nlexicon_favored['rating'] = pd.Series()\nlexicon_favored['lexicon_word'] = pd.Series()\nlexicon_favored['word_count'] = pd.Series()\n\nfor i,word in lex_nonzero.WORD.items():\n    for i2,piece in df_sample.comments.items():     \n        if word in word_tokenize(piece.lower()):\n            #print('index',i2,'\\nword',word, '\\npiece',piece.lower(), '\\nrating', lex_nonzero.RATING[i],'\\n')\n\n            # add rating from lexicon\n            lexicon_favored['rating'][i2] = lex_nonzero.RATING[i]\n\n            # add up every word usage in comments\n            lexicon_favored['lexicon_word'][i2] = lex_nonzero.WORD[i]\n            \n            # word count\n            lexicon_favored['word_count'][i2] = len(word_tokenize(piece.lower()))\n        else:\n            # word count\n            lexicon_favored['word_count'][i2] = len(word_tokenize(piece.lower()))\n            \nlexicon_favored = lexicon_favored\n#clear_output()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-26T01:51:31.99588Z","iopub.execute_input":"2023-09-26T01:51:31.996313Z","iopub.status.idle":"2023-09-26T01:54:28.547903Z","shell.execute_reply.started":"2023-09-26T01:51:31.996279Z","shell.execute_reply":"2023-09-26T01:54:28.546762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lexicon-Focused Dataset\n<br>\n\n#### Snippet","metadata":{}},{"cell_type":"code","source":"lexicon_favored.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T01:54:28.550006Z","iopub.execute_input":"2023-09-26T01:54:28.55115Z","iopub.status.idle":"2023-09-26T01:54:28.576056Z","shell.execute_reply.started":"2023-09-26T01:54:28.551109Z","shell.execute_reply":"2023-09-26T01:54:28.574879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"any(lexicon_favored.index.duplicated())","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-26T01:54:28.577343Z","iopub.execute_input":"2023-09-26T01:54:28.577803Z","iopub.status.idle":"2023-09-26T01:54:28.58359Z","shell.execute_reply.started":"2023-09-26T01:54:28.577775Z","shell.execute_reply":"2023-09-26T01:54:28.582594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n_ = plt.hist(lexicon_favored.word_count, bins='auto')  # arguments are passed to np.histogram\nplt.title(\"Word Counts Histogram with 'auto' bins\")\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T01:54:28.586439Z","iopub.execute_input":"2023-09-26T01:54:28.586833Z","iopub.status.idle":"2023-09-26T01:54:28.923229Z","shell.execute_reply.started":"2023-09-26T01:54:28.586779Z","shell.execute_reply":"2023-09-26T01:54:28.921983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# stopwords\nimport nltk\nfrom nltk.corpus import stopwords\n \n#nltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\n\nlexicon_favored['just_words'] = pd.Series()\nfiltered_sentence = []\n\nfor i,piece in lexicon_favored.comments.items():     \n    for word in word_tokenize(piece.lower()):\n        if word not in stop_words:\n            filtered_sentence.append({i, word})","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T01:54:28.924803Z","iopub.execute_input":"2023-09-26T01:54:28.925291Z","iopub.status.idle":"2023-09-26T01:54:29.199406Z","shell.execute_reply.started":"2023-09-26T01:54:28.925252Z","shell.execute_reply":"2023-09-26T01:54:29.198207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ranked by Lexicon Rating.","metadata":{}},{"cell_type":"code","source":"lexicon_favored = lexicon_favored.sort_values('rating',ascending=False).reset_index(drop=True)\nlexicon_favored.head(25).style.background_gradient(cmap ='seismic').set_properties(**{'font-size': '11px'})","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-09-26T01:54:29.20077Z","iopub.execute_input":"2023-09-26T01:54:29.201124Z","iopub.status.idle":"2023-09-26T01:54:29.25521Z","shell.execute_reply.started":"2023-09-26T01:54:29.201096Z","shell.execute_reply":"2023-09-26T01:54:29.254147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# \"Be careful not to choke on your aspirations.\" - Darth Vader\n### Application of [VADER](https://github.com/cjhutto/vaderSentiment) (Valence Aware Dictionary and sEntiment Reasoner)\nA lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media.","metadata":{}},{"cell_type":"code","source":"# https://www.geeksforgeeks.org/python-sentiment-analysis-using-vader/\n# https://github.com/cjhutto/vaderSentiment\n#\n# Natural Language Toolkit: vader - TAMPERED w/ SCU Lexicon\n#\n# Copyright (C) 2001-2023 NLTK Project\n# Author: C.J. Hutto <Clayton.Hutto@gtri.gatech.edu>\n#         Ewan Klein <ewan@inf.ed.ac.uk> (modifications)\n#         Pierpaolo Pantone <24alsecondo@gmail.com> (modifications)\n#         George Berry <geb97@cornell.edu> (modifications)\n#         Malavika Suresh <malavika.suresh0794@gmail.com> (modifications)\n# URL: <https://www.nltk.org/>\n\"\"\"\nIf you use the VADER sentiment analysis tools, please cite:\n\nHutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for\nSentiment Analysis of Social Media Text. Eighth International Conference on\nWeblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.\n\"\"\"\nimport math\nimport re\nimport string\nfrom itertools import product\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom IPython.display import clear_output\nimport nltk.data\nclear_output()\n\nclass VaderConstants:\n    \"\"\"\n    A class to keep the Vader lists and constants.\n    \"\"\"\n\n    ##Constants##\n    # (empirically derived mean sentiment intensity rating increase for booster words)\n    B_INCR = 0.293\n    B_DECR = -0.293\n\n    # (empirically derived mean sentiment intensity rating increase for using\n    # ALLCAPs to emphasize a word)\n    C_INCR = 0.733\n\n    N_SCALAR = -0.74\n\n    NEGATE = {'UFO',\n             'again',\n             'alien',\n             'another',\n             'attack',\n             'beam',\n             'beautiful',\n             'bed',\n             'bedroom',\n             'being',\n             'believe',\n             'capture',\n             'caught',\n             'chase',\n             'chemtrail',\n             'cloud',\n             'clouds',\n             'coming',\n             'confuse',\n             'contact',\n             'daily',\n             \"didn't\",\n             'discover',\n             'dream',\n             'earth',\n             'every',\n             'excited',\n             'experience',\n             'figure',\n             'fireball',\n             'firework',\n             'fireworks',\n             'frequent',\n             'happy',\n             'help',\n             'hope',\n             'less',\n             'me',\n             'mufon',\n             'needle',\n             'nightly',\n             'often',\n             'orange',\n             'pain',\n             'paranormal',\n             'please',\n             'presence',\n             'psychic',\n             'review',\n             'room',\n             'scared',\n             'seen',\n             'shock',\n             'shocked',\n             'skin',\n             'sleep',\n             'star-like',\n             'starlike',\n             'starship',\n             'storm',\n             'surgery',\n             'taken',\n             'their',\n             'thigh',\n             'tragedy',\n             'trance',\n             'ufo',\n             \"ufo's\",\n             'ufos',\n             'visit',\n             'visitation',\n             'want',\n             'zoom',\n             'zoomed'\n             }\n\n\n    # booster/dampener 'intensifiers' or 'degree adverbs'\n    # https://en.wiktionary.org/wiki/Category:English_degree_adverbs\n\n    BOOSTER_DICT = {\n        'northeastern'  : B_INCR,\n        'law'  : B_INCR,\n        'duty'  : B_INCR,\n        'appearing'  : B_INCR,\n        'background'  : B_INCR,\n        'clockwise'  : B_INCR,\n        'momentarily'  : B_INCR,\n        'degrees'  : B_INCR,\n        'appearance'  : B_INCR,\n        'approx'  : B_INCR,\n        'approximate'  : B_INCR,\n        'within'  : B_INCR,\n        'NORAD'  : B_INCR,\n        'plasma'  : B_INCR,\n        'astronomical'  : B_INCR,\n        'Lockheed'  : B_INCR,\n        'retire'  : B_INCR,\n        'locomotion'  : B_INCR,\n        'feather'  : B_INCR,\n        'seemed'  : B_INCR,\n        'witnesses'  : B_INCR,\n        'aviation'  : B_INCR,\n        'nuclear'  : B_INCR,\n        'air force'  : B_INCR,\n        'north'  : B_INCR,\n        'seem'  : B_INCR,\n        'fort'  : B_INCR,\n        'register'  : B_INCR,\n        'translucent'  : B_INCR,\n        'hexagon'  : B_INCR,\n        'normal'  : B_INCR,\n        'target'  : B_INCR,\n        'morning'  : B_INCR,\n        'rotar'  : B_INCR,\n        'southwest'  : B_INCR,\n        'AF'  : B_INCR,\n        'south'  : B_INCR,\n        'approach'  : B_INCR,\n        'opaque'  : B_INCR,\n        'hexagonal'  : B_INCR,\n        'guard'  : B_INCR,\n        'briefly'  : B_INCR,\n        'rectangular'  : B_INCR,\n        'upward'  : B_INCR,\n        'officer'  : B_INCR,\n        'telescope'  : B_INCR,\n        'propulsion'  : B_INCR,\n        'perimeter'  : B_INCR,\n        'traverse'  : B_INCR,\n        'army'  : B_INCR,\n        'eastern'  : B_INCR,\n        'elongate'  : B_INCR,\n        'customer'  : B_INCR,\n        'binoculars'  : B_INCR,\n        'pulled'  : B_INCR,\n        'emanate'  : B_INCR,\n        'scope'  : B_INCR,\n        'southern'  : B_INCR,\n        'assume'  : B_INCR,\n        'capability'  : B_INCR,\n        'radar'  : B_INCR,\n        'structure'  : B_INCR,\n        'tree-line'  : B_INCR,\n        'appear'  : B_INCR,\n        'western'  : B_INCR,\n        'defense'  : B_INCR,\n        'irregular'  : B_INCR,\n        'call'  : B_INCR,\n        'analyze'  : B_INCR,\n        'coast  '  : B_INCR,\n        'vertex'  : B_INCR,\n        'altitude'  : B_INCR,\n        'grid'  : B_INCR,\n        'blend'  : B_INCR,\n        'public'  : B_INCR,\n        'northern'  : B_INCR,\n        'simultaneous'  : B_INCR,\n        'perspective'  : B_INCR,\n        'capable'  : B_INCR,\n        'navy'  : B_INCR,\n        'degree'  : B_INCR,\n        'family'  : B_INCR,\n        'east'  : B_INCR,\n        'enforcement'  : B_INCR,\n        'position'  : B_INCR,\n        'F14'  : B_INCR,\n        'astronomy'  : B_INCR,\n        'police'  : B_INCR,\n        'base'  : B_INCR,\n        'security'  : B_INCR,\n        'velocity'  : B_INCR,\n        'similar'  : B_INCR,\n        'civilian'  : B_INCR,\n        'pilot'  : B_INCR,\n        'F15'  : B_INCR,\n        'southeastern'  : B_INCR,\n        'Boeing'  : B_INCR,\n        'counterclockwise'  : B_INCR,\n        'estimate'  : B_INCR,\n        'sentry'  : B_INCR,\n        'sheriff'  : B_INCR,\n        'assign'  : B_INCR,\n        'B2'  : B_INCR,\n        'cloak'  : B_INCR,\n        'west'  : B_INCR,\n        'northwest'  : B_INCR,\n        'military'  : B_INCR,\n        'marine'  : B_INCR,\n        'engine'  : B_INCR,\n        'reception'  : B_INCR,\n        'treeline'  : B_INCR,\n        '911'  : B_INCR,\n        'radio'  : B_INCR,\n        'southeast'  : B_INCR,\n        'height'  : B_INCR,\n        'rotating'  : B_INCR,\n        'rotate'  : B_INCR,\n        'octagonal'  : B_INCR,\n        'day'  : B_INCR,\n        'physics'  : B_INCR,\n        'border'  : B_INCR,\n        'northwestern'  : B_INCR,\n        'cluster'  : B_INCR,\n        'appeared'  : B_INCR,\n        'solid'  : B_INCR,\n        'rotary'  : B_INCR,\n        'horizontal'  : B_INCR,\n        'approximately'  : B_INCR,\n        'equidistant'  : B_INCR,\n        'independent'  : B_INCR,\n        'naval'  : B_INCR,\n        'policeman'  : B_INCR,\n        'resemble'  : B_INCR,\n        'northeast'  : B_INCR,\n        'commercial'  : B_INCR,\n        'southwestern'  : B_INCR,\n        'octagon'  : B_INCR,\n        'motion'  : B_INCR,\n        'deputy'  : B_INCR,\n        'daytime'  : B_INCR,\n        'flight'  : B_INCR,\n        'biologist'  : B_INCR,\n        'silo'  : B_INCR,\n        'patrol'  : B_INCR,\n        'chemist'  : B_INCR,\n        'perfect'  : B_INCR,\n        'astronomer'  : B_INCR,\n        'azimuth'  : B_INCR,\n        'radioed'  : B_INCR,\n        'elevation'  : B_INCR,\n        'coast guard'  : B_INCR,\n        'engineer'  : B_INCR,\n        'reports'  : B_DECR,\n        'towards'  : B_DECR,\n        'directions'  : B_DECR,\n        'attention'  : B_DECR,\n        'directly'  : B_DECR,\n        'friends'  : B_DECR,\n        'triangle'  : B_DECR,\n        'ft'  : B_DECR,\n        'pictures'  : B_DECR,\n        'event'  : B_DECR,\n        'father'  : B_DECR,\n        'observe '  : B_DECR,\n        'observing'  : B_DECR,\n        'extremely'  : B_DECR,\n        'standing'  : B_DECR,\n        'visible'  : B_DECR,\n        'spherical'  : B_DECR,\n        'angle'  : B_DECR,\n        'hover'  : B_DECR,\n        'triangular'  : B_DECR,\n        'location'  : B_DECR,\n        'diameter'  : B_DECR,\n        'direction'  : B_DECR,\n        'close'  : B_DECR,\n        'speed'  : B_DECR,\n        'hovered'  : B_DECR,\n        'between'  : B_DECR,\n        'object'  : B_DECR,\n        'glow'  : B_DECR,\n        'sister'  : B_DECR,\n        'clearly'  : B_DECR,\n        'never'  : B_DECR,\n        'trees'  : B_DECR,\n        'son'  : B_DECR,\n        'near'  : B_DECR,\n        'facing'  : B_DECR,\n        'movement'  : B_DECR,\n        'realized'  : B_DECR,\n        'photos'  : B_DECR,\n        'behind'  : B_DECR,\n        'witnessed'  : B_DECR,\n        'cloudy'  : B_DECR,\n        'immediate'  : B_DECR,\n        'notice'  : B_DECR,\n        'camera'  : B_DECR,\n        'large'  : B_DECR,\n        'brother'  : B_DECR,\n        'underneath'  : B_DECR,\n        'asked'  : B_DECR,\n        'closer'  : B_DECR,\n        'called'  : B_DECR,\n        'photo'  : B_DECR,\n        'yards'  : B_DECR,\n        'highway'  : B_DECR,\n        'down'  : B_DECR,\n        'objects'  : B_DECR,\n        'video'  : B_DECR,\n        'assumed'  : B_DECR,\n        'horizon'  : B_DECR,\n        'tree'  : B_DECR,\n        'station'  : B_DECR,\n        'mile'  : B_DECR,\n        'shape'  : B_DECR,\n        'together'  : B_DECR,\n        'ground'  : B_DECR,\n        'mountain'  : B_DECR,\n        'mother'  : B_DECR,\n        'observed'  : B_DECR,\n        'curious'  : B_DECR,\n        'fairly'  : B_DECR,\n        'feet'  : B_DECR,\n        'miles'  : B_DECR,\n        'ocean'  : B_DECR,\n        'below'  : B_DECR,\n        'brightness'  : B_DECR,\n        'bottom'  : B_DECR,\n        'hill'  : B_DECR,\n        'pattern'  : B_DECR,\n        'remember'  : B_DECR,\n        'daughter'  : B_DECR,\n        'hovering'  : B_DECR,\n        'joke'  : B_DECR,\n        'stationary'  : B_DECR,\n        'metallic'  : B_DECR,\n        'probably'  : B_DECR,\n        'top'  : B_DECR,\n        'might'  : B_DECR,\n        'approaching'  : B_DECR,\n        'slightly'  : B_DECR,\n        'smaller'  : B_DECR,\n        'toward'  : B_DECR,\n        'above'  : B_DECR,\n        'different'  : B_DECR,\n        'husband'  : B_DECR,\n        'glowing'  : B_DECR,\n        'mom'  : B_DECR,\n        'water'  : B_DECR,\n        'wasnt'  : B_DECR,\n        'path'  : B_DECR,\n        'friend'  : B_DECR,\n        'dad'  : B_DECR,\n        'observation'  : B_DECR,\n        'center'  : B_DECR,\n        'began'  : B_DECR,\n        'course'  : B_DECR,\n        'smoke'  : B_DECR,\n        'cigar'  : B_DECR,\n        'located'  : B_DECR,\n        'overhead'  : B_DECR,\n        'minutes'  : B_DECR,\n        'dog'  : B_DECR,\n        'witness'  : B_DECR,\n        'cold'  : B_DECR,\n        'report'  : B_DECR,\n        'wife'  : B_DECR,\n        'appears'  : B_DECR,\n        'bright'  : B_DECR,\n        'moon'  : B_DECR,\n        'moving'  : B_DECR,\n        'craft'  : B_DECR,\n        'brighter'  : B_DECR,\n    }\n\n    # check for special case idioms using a sentiment-laden keyword known to SAGE\n    SPECIAL_CASE_IDIOMS = {\n        \"the shit\": 3,\n        \"the bomb\": 3,\n        \"bad ass\": 1.5,\n        \"yeah right\": -2,\n        \"cut the mustard\": 2,\n        \"kiss of death\": -1.5,\n        \"hand to mouth\": -2,\n    }\n\n    # for removing punctuation\n    REGEX_REMOVE_PUNCTUATION = re.compile(f\"[{re.escape(string.punctuation)}]\")\n\n    PUNC_LIST = [\n        \".\",\n        \"!\",\n        \"?\",\n        \"&\",\n        \"#44\",\n        \",\",\n        \";\",\n        \":\",\n        \"-\",\n        \"'\",\n        '\"',\n        \"!!\",\n        \"!!!\",\n        \"??\",\n        \"???\",\n        \"?!?\",\n        \"!?!\",\n        \"?!?!\",\n        \"!?!?\",\n    ]\n\n    def __init__(self):\n        pass\n\n    def pairwise(iterable):\n        \"\"\"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\"\"\n        a, b = tee(iterable)\n        next(b, None)\n        return zip(a, b)\n    \n    def negated(self, input_words, include_nt=True):\n        \"\"\"\n        Determine if input contains negation words\n        \"\"\"\n        neg_words = self.NEGATE\n        if any(word.lower() in neg_words for word in input_words):\n            return True\n        if include_nt:\n            if any(\"n't\" in word.lower() for word in input_words):\n                return True\n        #for first, second in pairwise(input_words):\n        #    if second.lower() == \"least\" and first.lower() != \"at\":\n        #        return True\n        return False\n\n\n    def normalize(self, score, alpha=15):\n        \"\"\"\n        Normalize the score to be between -1 and 1 using an alpha that\n        approximates the max expected value\n        \"\"\"\n        norm_score = score / math.sqrt((score * score) + alpha)\n        return norm_score\n\n\n    def scalar_inc_dec(self, word, valence, is_cap_diff):\n        \"\"\"\n        Check if the preceding words increase, decrease, or negate/nullify the\n        valence\n        \"\"\"\n        scalar = 0.0\n        word_lower = word.lower()\n        if word_lower in self.BOOSTER_DICT:\n            scalar = self.BOOSTER_DICT[word_lower]\n            if valence < 0:\n                scalar *= -1\n            # check if booster/dampener word is in ALLCAPS (while others aren't)\n            if word.isupper() and is_cap_diff:\n                if valence > 0:\n                    scalar += self.C_INCR\n                else:\n                    scalar -= self.C_INCR\n        return scalar\n\n\n\nclass SentiText:\n    \"\"\"\n    Identify sentiment-relevant string-level properties of input text.\n    \"\"\"\n\n    def __init__(self, text, punc_list, regex_remove_punctuation):\n        if not isinstance(text, str):\n            text = str(text.encode(\"utf-8\"))\n        self.text = text\n        self.PUNC_LIST = punc_list\n        self.REGEX_REMOVE_PUNCTUATION = regex_remove_punctuation\n        self.words_and_emoticons = self._words_and_emoticons()\n        # doesn't separate words from\n        # adjacent punctuation (keeps emoticons & contractions)\n        self.is_cap_diff = self.allcap_differential(self.words_and_emoticons)\n\n\n    def _words_plus_punc(self):\n        \"\"\"\n        Returns mapping of form:\n        {\n            'cat,': 'cat',\n            ',cat': 'cat',\n        }\n        \"\"\"\n        no_punc_text = self.REGEX_REMOVE_PUNCTUATION.sub(\"\", self.text)\n        # removes punctuation (but loses emoticons & contractions)\n        words_only = no_punc_text.split()\n        # remove singletons\n        words_only = {w for w in words_only if len(w) > 1}\n        # the product gives ('cat', ',') and (',', 'cat')\n        punc_before = {\"\".join(p): p[1] for p in product(self.PUNC_LIST, words_only)}\n        punc_after = {\"\".join(p): p[0] for p in product(words_only, self.PUNC_LIST)}\n        words_punc_dict = punc_before\n        words_punc_dict.update(punc_after)\n        return words_punc_dict\n\n    def _words_and_emoticons(self):\n        \"\"\"\n        Removes leading and trailing puncutation\n        Leaves contractions and most emoticons\n            Does not preserve punc-plus-letter emoticons (e.g. :D)\n        \"\"\"\n        wes = self.text.split()\n        words_punc_dict = self._words_plus_punc()\n        wes = [we for we in wes if len(we) > 1]\n        for i, we in enumerate(wes):\n            if we in words_punc_dict:\n                wes[i] = words_punc_dict[we]\n        return wes\n\n    def allcap_differential(self, words):\n        \"\"\"\n        Check whether just some words in the input are ALL CAPS\n\n        :param list words: The words to inspect\n        :returns: `True` if some but not all items in `words` are ALL CAPS\n        \"\"\"\n        is_different = False\n        allcap_words = 0\n        for word in words:\n            if word.isupper():\n                allcap_words += 1\n        cap_differential = len(words) - allcap_words\n        if 0 < cap_differential < len(words):\n            is_different = True\n        return is_different\n\n\n\nclass SentimentIntensityAnalyzer:\n    \"\"\"\n    Give a sentiment intensity score to sentences.\n    \"\"\"\n\n    def __init__(\n        self,\n        lexicon_file=\"sentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\",\n    ):\n        self.lexicon_file = nltk.data.load(lexicon_file)\n        self.lexicon = self.make_lex_dict()\n        self.constants = VaderConstants()\n\n\n    def make_lex_dict(self):\n        \"\"\"\n        Convert lexicon file to a dictionary\n        \"\"\"\n        lex_dict = {}\n        for line in self.lexicon_file.split(\"\\n\"):\n            (word, measure) = line.strip().split(\"\\t\")[0:2]\n            lex_dict[word] = float(measure)\n        return lex_dict\n\n\n    def polarity_scores(self, text):\n        \"\"\"\n        Return a float for sentiment strength based on the input text.\n        Positive values are positive valence, negative value are negative\n        valence.\n\n        :note: Hashtags are not taken into consideration (e.g. #BAD is neutral). If you\n            are interested in processing the text in the hashtags too, then we recommend\n            preprocessing your data to remove the #, after which the hashtag text may be\n            matched as if it was a normal word in the sentence.\n        \"\"\"\n        # text, words_and_emoticons, is_cap_diff = self.preprocess(text)\n        sentitext = SentiText(\n            text, self.constants.PUNC_LIST, self.constants.REGEX_REMOVE_PUNCTUATION\n        )\n        sentiments = []\n        words_and_emoticons = sentitext.words_and_emoticons\n        for item in words_and_emoticons:\n            valence = 0\n            i = words_and_emoticons.index(item)\n            if (\n                i < len(words_and_emoticons) - 1\n                and item.lower() == \"kind\"\n                and words_and_emoticons[i + 1].lower() == \"of\"\n            ) or item.lower() in self.constants.BOOSTER_DICT:\n                sentiments.append(valence)\n                continue\n\n            sentiments = self.sentiment_valence(valence, sentitext, item, i, sentiments)\n\n        sentiments = self._but_check(words_and_emoticons, sentiments)\n\n        return self.score_valence(sentiments, text)\n\n\n    def sentiment_valence(self, valence, sentitext, item, i, sentiments):\n        is_cap_diff = sentitext.is_cap_diff\n        words_and_emoticons = sentitext.words_and_emoticons\n        item_lowercase = item.lower()\n        if item_lowercase in self.lexicon:\n            # get the sentiment valence\n            valence = self.lexicon[item_lowercase]\n\n            # check if sentiment laden word is in ALL CAPS (while others aren't)\n            if item.isupper() and is_cap_diff:\n                if valence > 0:\n                    valence += self.constants.C_INCR\n                else:\n                    valence -= self.constants.C_INCR\n\n            for start_i in range(0, 3):\n                if (\n                    i > start_i\n                    and words_and_emoticons[i - (start_i + 1)].lower()\n                    not in self.lexicon\n                ):\n                    # dampen the scalar modifier of preceding words and emoticons\n                    # (excluding the ones that immediately preceed the item) based\n                    # on their distance from the current item.\n                    s = self.constants.scalar_inc_dec(\n                        words_and_emoticons[i - (start_i + 1)], valence, is_cap_diff\n                    )\n                    if start_i == 1 and s != 0:\n                        s = s * 0.95\n                    if start_i == 2 and s != 0:\n                        s = s * 0.9\n                    valence = valence + s\n                    valence = self._never_check(\n                        valence, words_and_emoticons, start_i, i\n                    )\n                    if start_i == 2:\n                        valence = self._idioms_check(valence, words_and_emoticons, i)\n\n                        # future work: consider other sentiment-laden idioms\n                        # other_idioms =\n                        # {\"back handed\": -2, \"blow smoke\": -2, \"blowing smoke\": -2,\n                        #  \"upper hand\": 1, \"break a leg\": 2,\n                        #  \"cooking with gas\": 2, \"in the black\": 2, \"in the red\": -2,\n                        #  \"on the ball\": 2,\"under the weather\": -2}\n\n            valence = self._least_check(valence, words_and_emoticons, i)\n\n        sentiments.append(valence)\n        return sentiments\n\n\n    def _least_check(self, valence, words_and_emoticons, i):\n        # check for negation case using \"least\"\n        if (\n            i > 1\n            and words_and_emoticons[i - 1].lower() not in self.lexicon\n            and words_and_emoticons[i - 1].lower() == \"least\"\n        ):\n            if (\n                words_and_emoticons[i - 2].lower() != \"at\"\n                and words_and_emoticons[i - 2].lower() != \"very\"\n            ):\n                valence = valence * self.constants.N_SCALAR\n        elif (\n            i > 0\n            and words_and_emoticons[i - 1].lower() not in self.lexicon\n            and words_and_emoticons[i - 1].lower() == \"least\"\n        ):\n            valence = valence * self.constants.N_SCALAR\n        return valence\n\n    def _but_check(self, words_and_emoticons, sentiments):\n        words_and_emoticons = [w_e.lower() for w_e in words_and_emoticons]\n        but = {\"but\"} & set(words_and_emoticons)\n        if but:\n            bi = words_and_emoticons.index(next(iter(but)))\n            for sidx, sentiment in enumerate(sentiments):\n                if sidx < bi:\n                    sentiments[sidx] = sentiment * 0.5\n                elif sidx > bi:\n                    sentiments[sidx] = sentiment * 1.5\n        return sentiments\n\n    def _idioms_check(self, valence, words_and_emoticons, i):\n        onezero = f\"{words_and_emoticons[i - 1]} {words_and_emoticons[i]}\"\n\n        twoonezero = \"{} {} {}\".format(\n            words_and_emoticons[i - 2],\n            words_and_emoticons[i - 1],\n            words_and_emoticons[i],\n        )\n\n        twoone = f\"{words_and_emoticons[i - 2]} {words_and_emoticons[i - 1]}\"\n\n        threetwoone = \"{} {} {}\".format(\n            words_and_emoticons[i - 3],\n            words_and_emoticons[i - 2],\n            words_and_emoticons[i - 1],\n        )\n\n        threetwo = \"{} {}\".format(\n            words_and_emoticons[i - 3], words_and_emoticons[i - 2]\n        )\n\n        sequences = [onezero, twoonezero, twoone, threetwoone, threetwo]\n\n        for seq in sequences:\n            if seq in self.constants.SPECIAL_CASE_IDIOMS:\n                valence = self.constants.SPECIAL_CASE_IDIOMS[seq]\n                break\n\n        if len(words_and_emoticons) - 1 > i:\n            zeroone = f\"{words_and_emoticons[i]} {words_and_emoticons[i + 1]}\"\n            if zeroone in self.constants.SPECIAL_CASE_IDIOMS:\n                valence = self.constants.SPECIAL_CASE_IDIOMS[zeroone]\n        if len(words_and_emoticons) - 1 > i + 1:\n            zeroonetwo = \"{} {} {}\".format(\n                words_and_emoticons[i],\n                words_and_emoticons[i + 1],\n                words_and_emoticons[i + 2],\n            )\n            if zeroonetwo in self.constants.SPECIAL_CASE_IDIOMS:\n                valence = self.constants.SPECIAL_CASE_IDIOMS[zeroonetwo]\n\n        # check for booster/dampener bi-grams such as 'sort of' or 'kind of'\n        if (\n            threetwo in self.constants.BOOSTER_DICT\n            or twoone in self.constants.BOOSTER_DICT\n        ):\n            valence = valence + self.constants.B_DECR\n        return valence\n\n    def _never_check(self, valence, words_and_emoticons, start_i, i):\n        if start_i == 0:\n            if self.constants.negated([words_and_emoticons[i - 1]]):\n                valence = valence * self.constants.N_SCALAR\n        if start_i == 1:\n            if words_and_emoticons[i - 2] == \"never\" and (\n                words_and_emoticons[i - 1] == \"so\"\n                or words_and_emoticons[i - 1] == \"this\"\n            ):\n                valence = valence * 1.5\n            elif self.constants.negated([words_and_emoticons[i - (start_i + 1)]]):\n                valence = valence * self.constants.N_SCALAR\n        if start_i == 2:\n            if (\n                words_and_emoticons[i - 3] == \"never\"\n                and (\n                    words_and_emoticons[i - 2] == \"so\"\n                    or words_and_emoticons[i - 2] == \"this\"\n                )\n                or (\n                    words_and_emoticons[i - 1] == \"so\"\n                    or words_and_emoticons[i - 1] == \"this\"\n                )\n            ):\n                valence = valence * 1.25\n            elif self.constants.negated([words_and_emoticons[i - (start_i + 1)]]):\n                valence = valence * self.constants.N_SCALAR\n        return valence\n\n    def _punctuation_emphasis(self, sum_s, text):\n        # add emphasis from exclamation points and question marks\n        ep_amplifier = self._amplify_ep(text)\n        qm_amplifier = self._amplify_qm(text)\n        punct_emph_amplifier = ep_amplifier + qm_amplifier\n        return punct_emph_amplifier\n\n    def _amplify_ep(self, text):\n        # check for added emphasis resulting from exclamation points (up to 4 of them)\n        ep_count = text.count(\"!\")\n        if ep_count > 4:\n            ep_count = 4\n        # (empirically derived mean sentiment intensity rating increase for\n        # exclamation points)\n        ep_amplifier = ep_count * 0.292\n        return ep_amplifier\n\n    def _amplify_qm(self, text):\n        # check for added emphasis resulting from question marks (2 or 3+)\n        qm_count = text.count(\"?\")\n        qm_amplifier = 0\n        if qm_count > 1:\n            if qm_count <= 3:\n                # (empirically derived mean sentiment intensity rating increase for\n                # question marks)\n                qm_amplifier = qm_count * 0.18\n            else:\n                qm_amplifier = 0.96\n        return qm_amplifier\n\n    def _sift_sentiment_scores(self, sentiments):\n        # want separate positive versus negative sentiment scores\n        pos_sum = 0.0\n        neg_sum = 0.0\n        neu_count = 0\n        for sentiment_score in sentiments:\n            if sentiment_score > 0:\n                pos_sum += (\n                    float(sentiment_score) + 1\n                )  # compensates for neutral words that are counted as 1\n            if sentiment_score < 0:\n                neg_sum += (\n                    float(sentiment_score) - 1\n                )  # when used with math.fabs(), compensates for neutrals\n            if sentiment_score == 0:\n                neu_count += 1\n        return pos_sum, neg_sum, neu_count\n\n    def score_valence(self, sentiments, text):\n        if sentiments:\n            sum_s = float(sum(sentiments))\n            # compute and add emphasis from punctuation in text\n            punct_emph_amplifier = self._punctuation_emphasis(sum_s, text)\n            if sum_s > 0:\n                sum_s += punct_emph_amplifier\n            elif sum_s < 0:\n                sum_s -= punct_emph_amplifier\n\n            compound = self.constants.normalize(sum_s)\n            # discriminate between positive, negative and neutral sentiment scores\n            pos_sum, neg_sum, neu_count = self._sift_sentiment_scores(sentiments)\n\n            if pos_sum > math.fabs(neg_sum):\n                pos_sum += punct_emph_amplifier\n            elif pos_sum < math.fabs(neg_sum):\n                neg_sum -= punct_emph_amplifier\n\n            total = pos_sum + math.fabs(neg_sum) + neu_count\n            pos = math.fabs(pos_sum / total)\n            neg = math.fabs(neg_sum / total)\n            neu = math.fabs(neu_count / total)\n\n        else:\n            compound = 0.0\n            pos = 0.0\n            neg = 0.0\n            neu = 0.0\n\n        sentiment_dict = {\n            \"neg\": round(neg, 3),\n            \"neu\": round(neu, 3),\n            \"pos\": round(pos, 3),\n            \"compound\": round(compound, 4),\n        }\n\n        return sentiment_dict\n\n\n# function to print sentiments\n# of the sentence.\ndef sentiment_scores(sentence):\n\n    # Create a SentimentIntensityAnalyzer object.\n    sid_obj = SentimentIntensityAnalyzer()\n    sentiment_dict = sid_obj.polarity_scores(sentence)\n    \n    # create a list\n    results = []\n    results.append({\"% Positive\":sentiment_dict['pos'],\n                    \"% Negative\":sentiment_dict['neg'],\n                    \"% Neutral\":sentiment_dict['neu'],\n                    \"% Compound\":sentiment_dict['compound']\n                   })\n    results = pd.DataFrame(results)\n    return results\n\n# Apply to df['comments'] column.\ndef NLP_PowellScore(commentsColumns):\n    \n    # obtain each comment for 'comments' column\n    eachComment = [eachComment for i,eachComment in commentsColumns.items()]\n    eachComment = pd.Series(eachComment)\n                               \n    # vader.variables.PowellScore\n    PowellPositive = [v for v in list([sentiment_scores(sentimentAnalyzedComment)[\"% Positive\"][0] for i,sentimentAnalyzedComment in eachComment.items()])]\n    PowellNegative = [v for v in list([sentiment_scores(sentimentAnalyzedComment)[\"% Negative\"][0] for i,sentimentAnalyzedComment in eachComment.items()])]\n    PowellNeutral = [v for v in list([sentiment_scores(sentimentAnalyzedComment)[\"% Neutral\"][0] for i,sentimentAnalyzedComment in eachComment.items()])]\n    PowellCompound = [v for v in list([sentiment_scores(sentimentAnalyzedComment)[\"% Compound\"][0] for i,sentimentAnalyzedComment in eachComment.items()])]\n    \n    return PowellPositive,PowellNegative,PowellNeutral,PowellCompound","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T02:04:55.034277Z","iopub.execute_input":"2023-09-26T02:04:55.034714Z","iopub.status.idle":"2023-09-26T02:04:55.436358Z","shell.execute_reply.started":"2023-09-26T02:04:55.034681Z","shell.execute_reply":"2023-09-26T02:04:55.435532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reports sorted by Veracity\nWe also added the \"Rating\" score from Lexicon.","metadata":{}},{"cell_type":"code","source":"# let's only take a small sample - this will definitely take a few minutes, grab yourself some water...\nrobert = lexicon_favored.copy()#.sample(30000)\nrobert.rating.value_counts()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-26T01:58:28.675751Z","iopub.execute_input":"2023-09-26T01:58:28.676193Z","iopub.status.idle":"2023-09-26T01:58:28.688774Z","shell.execute_reply.started":"2023-09-26T01:58:28.676164Z","shell.execute_reply":"2023-09-26T01:58:28.687603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# defining Powell Scores by sentiment outputs: Positive, Negative, Neutral, Compound, & Rating\nrobert[\"PowellPositive\"] = NLP_PowellScore(robert['comments'])[0]\nrobert[\"PowellNegative\"] = NLP_PowellScore(robert['comments'])[1]\nrobert[\"PowellNeutral\"] = NLP_PowellScore(robert['comments'])[2]\nrobert[\"PowellCompound\"] = NLP_PowellScore(robert['comments'])[3]\n\n# PowellScore \nrobert[\"PowellScore\"] = robert[\"PowellCompound\"]#(robert[\"PowellPositive\"]-robert[\"PowellNegative\"])/robert[\"PowellNeutral\"]\n\n# veracity\nrobert[\"veracity\"] = robert[\"PowellScore\"]*robert[\"comment_length\"]*robert[\"rating\"] # FINALLY, THIS EQUATION ACCOUNTS FOR POWELL'S LEXICON RATINGS!\n\n# veracity is still very much in progress. we are looking for ways forward to \n# better define them. although, it is important to note that \"veracity\" will \n# be variable that is subjective to the type of datasets.\ncolumns = ['date posted','city','state','shape','comments',\n           'comment_length','latitude','longitude','duration (minutes)',\\\n           'PowellScore','veracity','rating','lexicon_word']\n\ndf1 = robert[columns].sort_values('veracity',ascending=False).reset_index(drop=True)\ndf1[df1['comment_length']>10].head(20)\\\n        .style.background_gradient(cmap ='seismic').set_properties(**{'font-size': '11px'})","metadata":{"execution":{"iopub.status.busy":"2023-09-26T02:04:59.626559Z","iopub.execute_input":"2023-09-26T02:04:59.627899Z","iopub.status.idle":"2023-09-26T02:07:16.312846Z","shell.execute_reply.started":"2023-09-26T02:04:59.627817Z","shell.execute_reply":"2023-09-26T02:07:16.312027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ovals seen in California","metadata":{}},{"cell_type":"code","source":"%%time\n# ca_oval\nca_oval = df1[df1.state=='ca'].reset_index(drop=True)\nca_oval = ca_oval[ca_oval['shape']=='oval']\n\n# only ovals\nca_oval_162 = ca_oval.sort_values(['latitude','longitude'])\nrobert_ca_oval_162 = ca_oval_162\nrobert_ca_oval_162[\"PowellPositive\"] = NLP_PowellScore(robert_ca_oval_162['comments'])[0]\nrobert_ca_oval_162[\"PowellNegative\"] = NLP_PowellScore(robert_ca_oval_162['comments'])[1]\nrobert_ca_oval_162[\"PowellNeutral\"] = NLP_PowellScore(robert_ca_oval_162['comments'])[2]\n\n# PowellScore \nrobert_ca_oval_162[\"PowellScore\"] = (robert_ca_oval_162[\"PowellPositive\"]-robert_ca_oval_162[\"PowellNegative\"])/robert_ca_oval_162[\"PowellNeutral\"]\n\n# veracity\nrobert_ca_oval_162[\"veracity\"] = robert_ca_oval_162[\"PowellScore\"]*robert_ca_oval_162[\"comment_length\"]*robert_ca_oval_162[\"rating\"]\n\n\ndf2 = robert_ca_oval_162[columns].sort_values(['veracity'],ascending=False).reset_index(drop=True)\ndf2.head(50).style.background_gradient(cmap ='seismic').set_properties(**{'font-size': '11px'})","metadata":{"execution":{"iopub.status.busy":"2023-09-26T02:07:16.314805Z","iopub.execute_input":"2023-09-26T02:07:16.315204Z","iopub.status.idle":"2023-09-26T02:07:16.891019Z","shell.execute_reply.started":"2023-09-26T02:07:16.315173Z","shell.execute_reply":"2023-09-26T02:07:16.890208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Powell Variables in 3D\nThis is a 3D-interactive chart that uses the date posted, veracity, & PowellScore variables. Colored by lexicon rating. Sized by comment_length.\n\nBy definition, these actually render 5-Dimensional charts, if one considers veracity & commenth lengths of reports as 'features of a situation'.","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\ndf_plot = df1[df1.rating>0]\n# graph\nfig = px.scatter_3d(df_plot, x='date posted', y='veracity', z='PowellScore',\n              color='rating',\n              size = 'comment_length',\n              hover_name = 'city',\n              hover_data=['city','state','comments','rating','lexicon_word'],              \n              opacity=0.5,\n              size_max=17\n                   )\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T02:07:16.893027Z","iopub.execute_input":"2023-09-26T02:07:16.89359Z","iopub.status.idle":"2023-09-26T02:07:18.782826Z","shell.execute_reply.started":"2023-09-26T02:07:16.893556Z","shell.execute_reply":"2023-09-26T02:07:18.78008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This one shows Date Posted vs PowellScore & Lexicon Rating Variables of California Oval reports. Colored by Veracity.","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\n# graph\nfig = px.scatter_3d(df1, x='date posted', y='PowellScore', z='rating',\n              color='veracity',\n              size = 'comment_length',\n              hover_name = 'city',\n              hover_data=['city','state','comments','rating','lexicon_word'],              \n              opacity=0.5,\n              size_max=17\n                   )\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T02:07:18.786005Z","iopub.execute_input":"2023-09-26T02:07:18.787064Z","iopub.status.idle":"2023-09-26T02:07:18.944354Z","shell.execute_reply.started":"2023-09-26T02:07:18.787011Z","shell.execute_reply":"2023-09-26T02:07:18.942877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ovals seen in California - Date Posted vs PowellNeutral vs PowellScore","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\n# graph\nfig = px.scatter_3d(robert_ca_oval_162, x='date posted', y='PowellNeutral', z='rating',\n              color='veracity',\n              size = 'comment_length',\n              hover_name = 'city',\n              hover_data=['city','state','comments','shape','veracity','rating'],              \n              opacity=0.5,\n              size_max=17\n                   )\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T02:07:18.94655Z","iopub.execute_input":"2023-09-26T02:07:18.947487Z","iopub.status.idle":"2023-09-26T02:07:19.023169Z","shell.execute_reply.started":"2023-09-26T02:07:18.947441Z","shell.execute_reply":"2023-09-26T02:07:19.021848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These variables are still very much in progress & there currently is no process for defining them. Despite the disparate, disconnected, & wide range of skeptic/non-skeptic relational databases — we have managed to connect with organizations that promote open source — public repositories & most are willing to coordinate with one another in developing a UAP Reporting & Events Hub. Wherein all pertinent reports, sightings, measurements, & signatures are to be populated by various factors from multiple disciplines & technologies. We will do our best to coordinate with prominent key members of the UAP community in order to contribute to building out a “standardized” reporting mechanism in an intelligible & non-duplicative fashion. We are looking for ways forward in getting access to real-time, current reports.\n\nThe goal would be to create something similar to an Order of Battle, so that reports at specific times & locations can be compared to past reports to augment credibility determination, as well as eventually be compared to known events that may explain them. Once those explanations are vetted, reports would be coded by likelihood of mundane vs anomalous, which would aid in the processing of similar events in the future.\n\nIn addition, we have already begun looking for trends over time, such as the time of day when reported events take place, & the type of object reported over the decades. The latter can be observed in the “Shapes by Share of Reports” chart, which provides indications of confirmation bias in observed behavior.\n\nFinally, big data analysis (alongside robust AI|ML|DS modeling techniques) could also provide insight into the development of improved collection & reporting processes, which currently appear to be undefined, improving the quality of the data we receive. — K. Kolbe.","metadata":{}},{"cell_type":"markdown","source":"# Different NLP Methods","metadata":{}},{"cell_type":"code","source":"df1[['comments']].sample(15).style.set_properties(**{'text-align': 'left'})","metadata":{"execution":{"iopub.status.busy":"2023-09-26T02:07:19.024561Z","iopub.execute_input":"2023-09-26T02:07:19.024898Z","iopub.status.idle":"2023-09-26T02:07:19.039182Z","shell.execute_reply.started":"2023-09-26T02:07:19.024871Z","shell.execute_reply":"2023-09-26T02:07:19.038051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets split up every word from every column & frame that in itself, call it \"words\"\na = [v.split(' ') for i,v in df1.comments.items()]\nflatlist=[]\nfor sublist in a:\n    for element in sublist:\n        flatlist.append(element)\ncomments = pd.DataFrame(flatlist, columns=['words'])\ncomments","metadata":{"execution":{"iopub.status.busy":"2023-09-26T02:07:19.040547Z","iopub.execute_input":"2023-09-26T02:07:19.040918Z","iopub.status.idle":"2023-09-26T02:07:19.063673Z","shell.execute_reply.started":"2023-09-26T02:07:19.040887Z","shell.execute_reply":"2023-09-26T02:07:19.062428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)\n\ncomments.words.value_counts().head(20)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T02:07:19.06638Z","iopub.execute_input":"2023-09-26T02:07:19.06675Z","iopub.status.idle":"2023-09-26T02:07:19.082469Z","shell.execute_reply.started":"2023-09-26T02:07:19.066719Z","shell.execute_reply":"2023-09-26T02:07:19.081076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comments.words.value_counts().head(50).plot(kind='barh',figsize=(15,7))","metadata":{"execution":{"iopub.status.busy":"2023-09-26T02:07:19.084047Z","iopub.execute_input":"2023-09-26T02:07:19.084427Z","iopub.status.idle":"2023-09-26T02:07:19.749205Z","shell.execute_reply.started":"2023-09-26T02:07:19.084397Z","shell.execute_reply":"2023-09-26T02:07:19.747697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# billy-boy!\n# isolate only \"adjectives, nouns, verbs, & adverbs\"","metadata":{"execution":{"iopub.status.busy":"2023-09-26T02:07:19.75407Z","iopub.execute_input":"2023-09-26T02:07:19.754442Z","iopub.status.idle":"2023-09-26T02:07:19.75912Z","shell.execute_reply.started":"2023-09-26T02:07:19.754412Z","shell.execute_reply":"2023-09-26T02:07:19.758306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visual Insights","metadata":{}},{"cell_type":"markdown","source":"## Word Clouds\n### All 500 samples.","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n# in the clouds\n# 500 samples \ncomment_words = ''\nstopwords = set(STOPWORDS)\n \n# iterate through the csv file\nfor val in df1.comments:\n     \n    # typecaste each val to string\n    val = str(val)\n \n    # split the value\n    tokens = val.split()\n     \n    # Converts each token into lowercase\n    for i in range(len(tokens)):\n        tokens[i] = tokens[i].lower()\n     \n    comment_words += \" \".join(tokens)+\" \"\n \nwordcloud = WordCloud(width = 1200, height = 600,\n                background_color ='white',\n                stopwords = stopwords,\n                min_font_size = 7,\n                colormap='twilight').generate(comment_words)\n \n# plot the WordCloud image                      \nplt.figure(figsize=(25,10), facecolor='None')\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\n \nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T02:07:19.760458Z","iopub.execute_input":"2023-09-26T02:07:19.761518Z","iopub.status.idle":"2023-09-26T02:07:21.886301Z","shell.execute_reply.started":"2023-09-26T02:07:19.761478Z","shell.execute_reply":"2023-09-26T02:07:21.885104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### California Ovals ","metadata":{}},{"cell_type":"code","source":"# in the clouds\n# california ovals\ncomment_words = ''\nstopwords = set(STOPWORDS)\n \n# iterate through the csv file\nfor val in df2.comments:\n     \n    # typecaste each val to string\n    val = str(val)\n \n    # split the value\n    tokens = val.split()\n     \n    # Converts each token into lowercase\n    for i in range(len(tokens)):\n        tokens[i] = tokens[i].lower()\n     \n    comment_words += \" \".join(tokens)+\" \"\n \nwordcloud = WordCloud(width = 1200, height = 600,\n                background_color ='white',\n                stopwords = stopwords,\n                min_font_size = 7,\n                colormap='twilight').generate(comment_words)\n \n# plot the WordCloud image                      \nplt.figure(figsize=(25,10), facecolor='None')\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\n \nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T02:07:21.887931Z","iopub.execute_input":"2023-09-26T02:07:21.888883Z","iopub.status.idle":"2023-09-26T02:07:23.208174Z","shell.execute_reply.started":"2023-09-26T02:07:21.888825Z","shell.execute_reply":"2023-09-26T02:07:23.204058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Top Veracity Comments","metadata":{}},{"cell_type":"code","source":"df1.reset_index(drop=True).set_index('veracity').head(20)[['comments','rating','lexicon_word','shape','city']]","metadata":{"execution":{"iopub.status.busy":"2023-09-26T02:07:23.210812Z","iopub.execute_input":"2023-09-26T02:07:23.211881Z","iopub.status.idle":"2023-09-26T02:07:23.23311Z","shell.execute_reply.started":"2023-09-26T02:07:23.211822Z","shell.execute_reply":"2023-09-26T02:07:23.232016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### California Ovals Comments","metadata":{}},{"cell_type":"code","source":"df2.set_index('veracity')[['comments','shape','city']]","metadata":{"execution":{"iopub.status.busy":"2023-09-26T02:07:23.235316Z","iopub.execute_input":"2023-09-26T02:07:23.235638Z","iopub.status.idle":"2023-09-26T02:07:23.250907Z","shell.execute_reply.started":"2023-09-26T02:07:23.235611Z","shell.execute_reply":"2023-09-26T02:07:23.249751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MUFON Data Exploitation\n## DaScient-VADER Sentiment Analyzer\n\nHere, we begin focusing on the lexicon analysis of each comment submission.","metadata":{}},{"cell_type":"code","source":"%%time\nimport pandas as pd\n!pip install xlrd\n# Pull in data\nmufon = pd.read_excel('/kaggle/input/scu-nlp-uap-lexicon/Powell with Comments.xls',sheet_name='mufon_cms_2017-04-09',header=0)\nwitnesses = pd.read_excel('/kaggle/input/scu-nlp-uap-lexicon/Powell with Comments.xls',sheet_name='Sheet1',header=0)\nmufon = mufon.dropna(how='all').copy()\nmufon.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T02:07:23.252399Z","iopub.execute_input":"2023-09-26T02:07:23.25275Z","iopub.status.idle":"2023-09-26T02:07:45.073803Z","shell.execute_reply.started":"2023-09-26T02:07:23.25272Z","shell.execute_reply":"2023-09-26T02:07:45.072597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# diminish the mufon dataset\nimport numpy as np\nmufon1 = mufon[mufon.Witnesses>0]\nmufon1 = mufon1[mufon1.Length<3000]","metadata":{"execution":{"iopub.status.busy":"2023-09-26T02:07:45.075207Z","iopub.execute_input":"2023-09-26T02:07:45.07553Z","iopub.status.idle":"2023-09-26T02:07:45.110992Z","shell.execute_reply.started":"2023-09-26T02:07:45.075503Z","shell.execute_reply":"2023-09-26T02:07:45.109737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mufon1.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T02:07:45.112287Z","iopub.execute_input":"2023-09-26T02:07:45.112583Z","iopub.status.idle":"2023-09-26T02:07:45.136486Z","shell.execute_reply.started":"2023-09-26T02:07:45.112557Z","shell.execute_reply":"2023-09-26T02:07:45.135285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport time\nfrom nltk.tokenize import word_tokenize\n\ndf_sample1 = mufon1.sample(5000)\n\n# hash through each comment to find only those that include non-zero lexicon words\nlexicon_favored1 = df_sample1.copy()\nlexicon_favored1['rating'] = pd.Series()\nlexicon_favored1['lexicon_word'] = pd.Series()\nlexicon_favored1['word_count'] = pd.Series()\n\nfor i,word in lex_nonzero.WORD.items():\n    for i2,piece in df_sample1['Detailed Description'].items():\n        if word in word_tokenize(piece.lower()):\n            #print('index',i2,'\\nword',word, '\\npiece',piece.lower(), '\\nrating', lex_nonzero.RATING[i],'\\n')\n\n            # add rating from lexicon\n            lexicon_favored1['rating'][i2] = lex_nonzero.RATING[i]\n\n            # add up every word usage in comments\n            lexicon_favored1['lexicon_word'][i2] = lex_nonzero.WORD[i]\n            \n            # word count\n            lexicon_favored1['word_count'][i2] = len(word_tokenize(piece.lower()))\n        else:\n            # word count\n            lexicon_favored1['word_count'][i2] = len(word_tokenize(piece.lower()))\n#clear_output()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T02:07:45.138065Z","iopub.execute_input":"2023-09-26T02:07:45.138381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lexicon_favored1.to_csv('lexicon_favored1.csv',index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Natural Language Toolkit: vader (VADER SCU UAP Lexicon - Notebook)\n# One idea for diminishing computation time - Separate corpora by Date of Submission or by some known variable.\nPowellScore = (0,1) = (Emotional, Scientific)\nMODEL = ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#mufon = mufon.sample(30)\n# defining Powell Scores by sentiment outputs: Positive, Negative, & Neutral\nlexicon_favored1[\"PowellPositive\"] = NLP_PowellScore(lexicon_favored1['Detailed Description'])[0]\nlexicon_favored1[\"PowellNegative\"] = NLP_PowellScore(lexicon_favored1['Detailed Description'])[1]\nlexicon_favored1[\"PowellNeutral\"] = NLP_PowellScore(lexicon_favored1['Detailed Description'])[2]\nlexicon_favored1[\"PowellCompound\"] = NLP_PowellScore(lexicon_favored1['Detailed Description'])[3]\n\n# PowellScore \nlexicon_favored1[\"PowellScore\"] = (lexicon_favored1[\"PowellPositive\"]-lexicon_favored1[\"PowellNegative\"])/lexicon_favored1[\"PowellNeutral\"]\n\n# veracity\nlexicon_favored1[\"veracity\"] = lexicon_favored1[\"PowellScore\"]*lexicon_favored1[\"Length\"]*lexicon_favored1[\"Score\"]\n\ndf3 = lexicon_favored1.sort_values('veracity',ascending=False).reset_index(drop=True)\ndf3.head(100)\\\n        .style.background_gradient(cmap ='seismic').set_properties(**{'font-size': '11px'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3.to_csv('mufon_lexicon.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Science on MUFON Reports","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import confusion_matrix\n\n# encoding\nfrom sklearn.preprocessing import LabelEncoder\n\ndef encode(df):\n    lb_make = LabelEncoder()\n    columns = df.columns.values.tolist()\n    df_encoded = df[columns].copy()\n\n    # categorize/encode\n    for i in columns:\n        df_encoded[i] = lb_make.fit_transform(df[i])\n\n    # encoded\n    return df_encoded\n\n\n# encoded variable re-mapping\ndef encoding_remap(df, df_encoded, target):\n    \n    X_test = X_y_sets(df, target)[0][0]\n    \n    remap = pd.merge(df_encoded.loc[df_encoded.index.isin(X_test.index.values)][target].reset_index(),\n              df.loc[df.index.isin(X_test.index.values)][[target]].reset_index(),on=['index'])\n    \n    remap[target] = [str(remap[f'{target}_y'][i]) for i,v in remap[f'{target}_x'].items()]\n    remap['index'] = np.array([str(remap[f'{target}_x'][i]) for i,v in remap[f'{target}_x'].items()]).astype(int)\n    remap=remap[[target,'index']]\n    remap = remap.set_index('index').drop_duplicates().sort_values('index')\n    \n    return remap\n\n\n# pairplot\nimport seaborn as sns\ndef pairplot(df, target):\n    return sns.pairplot(df.sample(int(len(df/10000))),hue=target)\n    \n    \n# create X,y variables for ML\nfrom sklearn.model_selection import train_test_split\ndef X_y_sets(df, target):\n    X = df.dropna().drop(columns=[target]).copy()\n    y = df.dropna()[target].ravel().copy()\n    \n    return train_test_split(X, y, test_size=0.33, random_state=42), X, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# is scaling necessary?\n# construction of ML dataframes\ntarget = 'Disposition'#''veracity','PowellScore','NLP_PowellScore'\n\n# copy\na = lexicon_favored1[['Witnesses','Score','Length','Nearest City','State',\\\n        'Object Shape Primary','Exact Latitude','Exact Longitude','Disposition','veracity','PowellScore']].copy()\n\n# for the sake of computationa efficiency\na = a.head(10000).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find random sample & save index for defining an encoded use-case\nfrom random import randrange\nidx = randrange(len(a))\n\n# print random configuration item\nprint(\"\\nThis is a randomly chosen subject we will try to predict.\")\nb = pd.DataFrame(a.loc[idx]).T\nprint(f\"\\nTarget:'{target}' value is: \",b.reset_index()[target][0],\"\\n\")\n\n# store sol'n\nsolution = str(b.reset_index()[target][0])\n\n# print data point\nb\n# if this cell fails, try it again from step 1 - you ran into a null variable (i'll fix that soon enough)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# categorize/encode entire dataframe(a)\nc = encode(a)\nprint(\"\\nOriginal dataframe encoded into something we can run a classifier against.\\n\")\nc.sample(10).reset_index(drop=True).style.background_gradient(cmap ='Pastel1').set_properties(**{'font-size': '10px'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 'comments' & 'country' - out\nsns.pairplot(c[['Witnesses','Score','Length','Nearest City','State','Object Shape Primary','Exact Latitude','Exact Longitude','Disposition','veracity','PowellScore']]\\\n             .sample(100).copy(),\n             hue=f'{target}',\n             kind=\"kde\",\n             corner=True,\n             palette=\"Paired\"\n            )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print encoded item\nuse_case = pd.DataFrame(c.loc[idx]).T.drop(columns=[target]) \n\n#c\n\n# print encoded item w/out target info\ndata = c.drop(columns=[target]) \n\nprint(\"\\nThis is what our encoded 'use-case' looks like - number form, just the way the machine likes it.\\n\")\n\nuse_case.style.background_gradient(cmap ='twilight').set_properties(**{'font-size': '10px'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create X,y variables for ML\n# save trainer\nprint(\"\\nResetting train data...\\nCreating X-matrix & y-vector (target) for classification.\")\ntrainer = c.loc[c.index!=idx].copy()\nX, y =  trainer.drop(columns=[target]), trainer[target].ravel()\nX_train, X_test, y_train, y_test = X_y_sets(trainer, target)[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['target'] = pd.Series(y_train)\nX_train.dropna().head().reset_index(drop=True).reset_index(drop=True).style.background_gradient(cmap ='twilight').set_properties(**{'font-size': '10px'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for the sake of adding the 'target' column above for sake of layman's explanation\nX_train, X_test, y_train, y_test = X_y_sets(trainer, target)[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoded variable re-mapping\n# specific to our current target choice\nd = encoding_remap(a, c, target)\nprint(\"\\nDecoding our encoded dataframe to correlate with the initial randomly chosen subject.\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n-Live prediction-\\nThinking...\\n\")\n\n# MLP\nclf = MLPClassifier(alpha=0.666, max_iter=666).fit(X_train, y_train)\n\nprint()\nprint(\"Test score (confidence): \",clf.score(X_test, y_test)*100,\"%\")\nprint()\nprediction = clf.predict(use_case)[0]\nprint(f\"Prediction {target} index:\",prediction)\n\n# print decoded prediction\nprint(\"\\nPrediction Decoded\")\ne = d[d.index == prediction]\ne","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"solved = str(e['Disposition'][e.index[0]])\nif solution == solved:\n    print(f\"\\nYUP!\\n\\nThe machine's prediction against target variable '{target}' was correct!\\n\")\nelse:\n    print(\"\\nNOPE!\\nThe machine's prediction was incorrect :(\")\n    \nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# en fin","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}